import streamlit as st
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import pandas as pd

st.set_page_config(page_title="Pools Ferm√©es - Krystal", layout="wide")
st.title("üíß Pools de Liquidit√© Ferm√©es (Krystal)")

# URL d'entr√©e utilisateur
url = st.text_input("üîó Entrez l'URL d'une strat√©gie Krystal :", placeholder="https://krystal.app/strategies/9700")

def scrape_krystal_positions(strategy_url):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        page.goto(strategy_url)

        # Clic sur l'onglet "Positions"
        try:
            page.click("text=Positions")
            page.wait_for_selector(".token-symbol", timeout=10000)  # Attente que le tableau charge
        except Exception as e:
            st.error("‚ùå Erreur : Impossible de charger l'onglet Positions.")
            browser.close()
            return pd.DataFrame()

        html = page.content()
        browser.close()

    soup = BeautifulSoup(html, "html.parser")

    # Exemple de parsing bas√© sur ta capture ‚Äî √† adapter si besoin
    rows = soup.select("tr")  # Peut-√™tre ".table-row" si identifiable
    data = []

    for row in rows:
        try:
            token_pair = row.select_one(".token-symbol").text.strip()
            total_value = float(row.select_one(".total-value").text.replace("$", "").replace(",", "").strip())

            if total_value == 0:
                data.append({
                    "Token Pair": token_pair,
                    "Fees Generated": row.select_one(".fees").text.strip(),
                    "Deposits": row.select_one(".deposits").text.strip(),
                    "Withdrawals": row.select_one(".withdrawals").text.strip(),
                    "PnL": row.select_one(".pnl").text.strip(),
                    "Age": row.select_one(".age").text.strip(),
                    "Price Range": row.select_one(".price-range").text.strip()
                })
        except:
            continue

    return pd.DataFrame(data)

# ‚ö° Lancer l'analyse si URL valide
if url:
    with st.spinner("üîÑ Chargement des donn√©es..."):
        df = scrape_krystal_positions(url)

    if not df.empty:
        st.success(f"‚úÖ {len(df)} pool(s) ferm√©e(s) trouv√©e(s)")
        st.dataframe(df, use_container_width=True)
    else:
        st.warning("Aucune pool ferm√©e d√©tect√©e ou chargement √©chou√©.")
